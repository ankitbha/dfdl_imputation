
This tutorial will first explain the structure of the BEELINE repository,
with a walkthrough of the different components that the user can customize.


Project outline
###############

The BEELINE repository is structured as follows:

.. code:: text

          BEELINE
          |-- inputs/
          |   `-- examples/
          |       `-- GSD/
          |           |--refNetwork.csv
          |           |--PseudoTime.csv
          |           `--ExpressionData.csv
          |-- config-files/
          |   `-- config.yaml
          |-- BLRun/
          |   |-- sinceritiesRunner.py
          |   `-- ...
          |-- BLPlot/
          |   |-- NetworkMotifs.py  
          |   `-- CuratedOverview.py
          |-- BLEval/
          |   |-- parseTime.py
          |    `-- ...
          |-- Algorithms/
          |     |-- SINCERITIES/
          |     `-- ...
          |-- LICENSE
          |-- initialize.sh
          |-- BLRunner.py
          |-- BLEvaluator.py
          |-- README.md
          `-- requirements.txt

.. _input-datasets:

Input Datasets
##############

The sample input data set provided is generated by :ref:`BoolODE`
using the Boolean model of `Gonadal Sex Determination
<https://www.ncbi.nlm.nih.gov/pubmed/26573569>`_ as input.  Note that
this dataset has been pre-processed to produce three files that are
required in the BEELINE pipline. 

1. `ExpressionData.csv` contains the RNAseq data, with genes as
   rows and cell IDs as columns. This file is a required input to the
   pipline. Here is a `sample ExpressionData.csv file <https://github.com/Murali-group/Beeline/blob/master/inputs/example/GSD/ExpressionData.csv>`_
2. `PseudoTime.csv` contains the pseudotime values for the cells in
   `ExpressionData.csv`.  We recommend using the Slingshot method to
   obtain the pseudotime for a dataset. Many algorithms in the
   pipeline require a pseudotime file as input. Here is a `sample
   PseudoTime file
   <https://github.com/Murali-group/Beeline/blob/master/inputs/example/GSD/PseudoTime.csv>`_.
3. `refNetwork.csv` contains the ground truth network underlying the
   interactions between genes in `ExpressionData.csv`. Typically this
   network is not available, and will have to be curated from various
   Transcription Factor databases. While this file is not a
   requirement to run the base pipeline, a reference network is
   required to run some of the performance evaluations in
   :ref:`BLEval`.  Here is a `sample refNetwork.csv file
   <https://github.com/Murali-group/Beeline/blob/master/inputs/example/GSD/refNetwork.csv>`_


The figure below shows the t-SNE visualization of the expression
data from the example dataset.

.. image:: figs/SlingshotOutputVis.png

This dataset shows a bifurcating
trajectory, as is evidenced by the part (a) of the figure, where
each 'cell' is colored by the timepoint at which it was sampled
in the simulation (the darker colors indicate earlier time points).
Clustering the simulation confirms the two trajectories, indicated
in red and blue respectively in part (b). Finally, running Slingshot
on this dataset and specifying the cluster of cells corresponding to
the early time points yields two pseudotime trajectories, shown in part (c).
For details on the generation of this simulated dataset, see :ref:`boolode`.
           

.. attention:: Please ensure that any input dataset you create is
               comma separated, and contains the correct style of
               column names.


.. _configfiles:
               
Config files
############

Beeline uses `YAML <https://yaml.org/>`_ files to allow users to
flexibly specify inputs and algorithm run parameters. A sample config
file is provided in `here
<https://github.com/Murali-group/Beeline/blob/master/config-files/config.yaml>`_. A
config file should contain at minimum

.. code:: text

          input_settings:
              input_dir : "Base input directory name, relative to current working directory (recommended: inputs)"
              dataset_dir: "Subdirectory of input_dir where the datasets are placed in"
              datasets:
                  - name: "Dataset name"
                    exprData: "Expression Data filename"
                    cellData: "PseudoTime filename"
                    trueEdges: "Ground truth network filename"
              algorithms:
                  - name: "Algorithm name"
                    params:
                        # Any other parameters that can be passed to
                        # this algorithm
                        should_run: [True] # or False
                        
          output_settings:
              output_dir : "Base output directory name, relative to current working directory (recommended: outputs)"
              output_prefix: "Prefix for writing evaluation summary files"
               

Apart from indicating the path to the base directory and the specific
folder containing the input, the config file indicates which
algorithms should be run, along with the parameters to be passed to
the algorithms, if any. For a list of parameters that the pipeline
currently passes to the algorithms, see  :ref:`algorithms`.  Finally,
the YAML file also specifies the output_dir where the outputs are written.
Note that the output directory structure under output_dir is same
as the input directory strucutre under input_dir. For example, if the config file
contains the following:

.. code:: text

          input_settings:
              input_dir : "inputs"
              dataset_dir: "example"
              datasets:
                  - name: "GSD"
                    exprData: "ExpressionData.csv"
                    cellData: "PseudoTime.csv"
                    trueEdges: "refNetwork.csv"
              algorithms:
                  - name: "PIDC"
                    params:
                        should_run: [True]
                  - name: "SCODE"
                    params:
                        should_run: [False]
                        z: [10]
                        nIter: [1000]
                        nRep: [6]
                        
          output_settings:
              output_dir : "outputs"
              output_prefix: "GSD"



BEELINE would interepret this as follows: 

- The input expression data file is located at ``inputs/example/GSD/ExpressionData.csv``, the pseudotime file is located at ``inputs/example/GSD/PseudoTime.csv``, and the reference network or true edges file is located at ``inputs/example/GSD/refNetwork.csv``. Note that the paths are relative to the current working directory. 
- The algorithm specific inputs will be placed under ``inputs/example/GSD/<algorithm_name>``. For example, for PIDC, the inputs will be placed under ``inputs/example/GSD/PIDC/``. The SCODE algorithm will be skipped becuase the should_run flag is set to False. 
- The output folder structure will be similar to that of the inputs under output_dir. For example, the outputs obtained after running PIDC on this dataset will be placed under ``outputs/example/GSD/PIDC/``. 


.. attention:: Please ensure that the YAML file is correctly indented!

Running the pipeline
####################

Once the input dataset has been generated and formatted as described
in Section :ref:`input-datasets` , and the config file has been
created as described in :ref:`configfiles`, the pipeline can be
executed by simply calling ``BLRun.py`` with the config file
specifying the inputs and the algorithms to run, passed using the
``--config`` option which takes the path to the config file.

To run the pipeline, simply invoke

.. code:: bash

          python BLRunner.py --config PATH/TO/CONFIG/FILE

For details about the implementation of :class:`BLRun` , see :ref:`blrunguide` .

Running the evaluation scripts
##############################

Each algorithm outputs an inferred network in the form of a ranked edge list.
BEELINE implements a consistent interface using the config file in order to retrieve
the predictions of multiple algorithms and evaluate them using a variety of methods.

The evaluation of the inferred networks is done by calling the
``BLEvaluator.py`` script.  Like the ``BLRunner.py`` script, the
Evaluator script takes the config file as input. Every  subsequent
option passed to this script calls a different evaluation script. For instance,
in order to analyze the AUROC and AUPRC values, and also analyze network motifs,
use the following command

.. code:: bash

          python BLEvaluator.py --config PATH/TO/CONFIG/FILE \
                                     --auc \ # calls the computeAUC script
                                     --motifs \ # calls the computeNetMotifs script


The full list of available evaluation functions and their corresponding options to
be passed to ``BLEvaluator.py`` are given below:


.. csv-table::
  :widths: 30, 50
    
  "-h, --help","show the help message and exit"
  "-c, --config <file-name>","Configuration file containing list of datasets, algorithms, and output specifications."
  "-a, --auc","Compute median of areas under Precision-Recall and ROC curves. Calls :mod:`BLEval.computeAUC`."
  "-j, --jaccard","Compute median Jaccard index of predicted top-k networks
  for each algorithm for a given set of datasets generated from the same 
  ground truth network. Calls :mod:`BLEval.computeJaccard`."
  "-r, --spearman","Compute median Spearman Corr. of predicted edges for each algorithm for a given set of datasets generated from the same ground truth network.  Calls :mod:`BLEval.computeSpearman`."
  "-t, --time","Analyze time taken by each algorithm for a. Calls :mod:`BLEval.parseTime`."
  "-e, --epr","Compute median early precision. Calls :mod:`BLEval.computeEarlyPrec`."
  "-s, --sepr","Analyze median (signed) early precision for activation and inhibitory edges. :mod:`BLEval.computeSignedEPrec`."
  "-m, --motifs","Compute network motifs in the predicted top-k networks. Calls :mod:`BLEval.computeNetMotifs`"

For details about the implementation of :class:`BLEval` , see :ref:`blevalguide` .
