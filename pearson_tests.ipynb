{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/venv/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from consolidated_runs import run_simulations\n",
    "\n",
    "from Pearson.pearson import Pearson\n",
    "\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_with_proportion(total, targets, proportion):\n",
    "    total_sample = 10\n",
    "    num_special = int(total_sample * proportion)\n",
    "    special = np.random.choice(targets, num_special, replace=False)\n",
    "\n",
    "    remaining = list(set(total) - set(targets))\n",
    "    normal = np.random.choice(remaining, total_sample - num_special, replace=False)\n",
    "\n",
    "    final = np.concatenate([special, normal])\n",
    "    np.random.shuffle(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = range(1, 4) # DS3\n",
    "run_simulations(datasets,\n",
    "            sergio=True,\n",
    "            saucie=True, \n",
    "            scScope=True, \n",
    "            deepImpute=True, \n",
    "            magic=True, \n",
    "            genie=False,\n",
    "            arboreto=False,\n",
    "            pearson=False,\n",
    "            roc=False,\n",
    "            precision_recall_k=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations\n",
      "(9, 100, 300)\n",
      "(9, 400, 300)\n",
      "(9, 1200, 300)\n"
     ]
    }
   ],
   "source": [
    "imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "print(imp_dir)\n",
    "for i in range(1, 4):\n",
    "    load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "    save_name = 'DS6_expr.npy'\n",
    "\n",
    "    expr = np.load(os.path.join(load_dir, save_name))\n",
    "    print(expr.shape)\n",
    "    file_name = 'expr_shape.csv'\n",
    "    if not os.path.exists(os.path.join(load_dir, file_name)):\n",
    "        npfile = np.load(os.path.join(load_dir, save_name))\n",
    "        shap = npfile.shape\n",
    "        print(shap)\n",
    "        df = pd.DataFrame([shap])\n",
    "        df.to_csv(load_dir + '/' + file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "\n",
    "def run_pearson_ranking(proportion):\n",
    "    print(\"Running Pearson ranking tests with proportion\", proportion)\n",
    "    for i in range(1, 4):\n",
    "        gt_file = None\n",
    "        if i == 1:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/gt_GRN.csv'\n",
    "        elif i == 2:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/gt_GRN.csv'\n",
    "        elif i == 3:\n",
    "            gt_file = 'SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/gt_GRN.csv'\n",
    "        \n",
    "        # For now, just load clean data, save as csv, and load it back in\n",
    "        methods = ['Clean', 'Noisy', 'SAUCIE', 'scScope', 'DeepImpute', 'MAGIC']\n",
    "        file_name = ''\n",
    "        save_name = ''\n",
    "        for method in methods:\n",
    "            if method == 'Clean':\n",
    "                file_name = f'DS6_clean.npy'\n",
    "                save_name = f'DS6_clean.csv'\n",
    "            elif method == 'Noisy':\n",
    "                file_name = f'DS6_45.npy'\n",
    "                save_name = f'DS6_45.csv'\n",
    "            elif method == 'SAUCIE':\n",
    "                file_name = f'yhat_SAUCIE.npy'\n",
    "                save_name = f'yhat_SAUCIE.csv'\n",
    "            elif method == 'scScope':\n",
    "                file_name = f'yhat_scScope.npy'\n",
    "                save_name = f'yhat_scScope.csv'\n",
    "            elif method == 'DeepImpute':\n",
    "                file_name = f'yhat_deepImpute.npy'\n",
    "                save_name = f'yhat_deepImpute.csv'\n",
    "            elif method == 'MAGIC':\n",
    "                file_name = f'yhat_MAGIC_t_auto.npy'\n",
    "                save_name = f'yhat_MAGIC_t_auto.csv'\n",
    "            load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "            if not os.path.exists(os.path.join(imp_dir, f'DS{i}', save_name)):\n",
    "                npfile = np.load(load_dir + '/' + file_name)\n",
    "                df = pd.DataFrame(npfile)\n",
    "                df.to_csv(load_dir + '/' + save_name, index=False)\n",
    "            clean_df = pd.read_csv(os.path.join(load_dir, save_name))\n",
    "            \n",
    "            # Read ground truth\n",
    "            gt = pd.read_csv(gt_file, header=None)\n",
    "            confirmed_genes = gt[0].unique()\n",
    "\n",
    "            # Run Pearson on clean and noisy data\n",
    "            pearson = Pearson(np.transpose(clean_df), '')\n",
    "            p_values = pearson.values\n",
    "            np.fill_diagonal(p_values, 0)\n",
    "            pearson = pd.DataFrame(p_values, index=pearson.columns, columns=pearson.columns)\n",
    "\n",
    "            total = 0\n",
    "            for r in range(50):\n",
    "                sampled = sample_with_proportion(clean_df.index.tolist(), confirmed_genes, proportion)\n",
    "            # Take subset of pearson data with only the sampled genes\n",
    "                p_subset = pearson.loc[sampled]\n",
    "            #print(p_subset)\n",
    "            # Rank the expression pairs by the absolute value of the pearson correlation\n",
    "                melted = pd.melt(p_subset.reset_index(), id_vars=['index'], value_vars=p_subset.columns)\n",
    "                melted.columns = ['input', 'target', 'correlation']\n",
    "                melted_sorted = melted.sort_values(by='correlation', ascending=False)\n",
    "                ranked_list = list(melted_sorted.itertuples(index=False, name=None))[:10]\n",
    "            # Calculate the proportion of confirmed genes in the top k of the ranked pairs\n",
    "                top_10 = [(input, target) for input, target, _ in ranked_list]\n",
    "                true_pairs = set(tuple(x) for x in gt.values)\n",
    "                matches = sum(1 for pair in top_10 if pair in true_pairs)\n",
    "                prop = matches / len(top_10)\n",
    "                total += prop\n",
    "\n",
    "            print(f\"DS{i}\", method, total / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Pearson ranking tests with proportion 0.1\n",
      "DS1 Clean 0.17999999999999997\n",
      "DS1 Noisy 0.042\n",
      "DS1 SAUCIE 0.0\n",
      "DS1 scScope 0.0\n",
      "DS1 DeepImpute 0.0\n",
      "DS1 MAGIC 0.0\n",
      "DS2 Clean 0.18799999999999997\n",
      "DS2 Noisy 0.002\n",
      "DS2 SAUCIE 0.0\n",
      "DS2 scScope 0.002\n",
      "DS2 DeepImpute 0.002\n",
      "DS2 MAGIC 0.0\n",
      "DS3 Clean 0.16999999999999996\n",
      "DS3 Noisy 0.0\n",
      "DS3 SAUCIE 0.004\n",
      "DS3 scScope 0.0\n",
      "DS3 DeepImpute 0.002\n",
      "DS3 MAGIC 0.0\n",
      "Running Pearson ranking tests with proportion 0.2\n",
      "DS1 Clean 0.374\n",
      "DS1 Noisy 0.05199999999999999\n",
      "DS1 SAUCIE 0.004\n",
      "DS1 scScope 0.0\n",
      "DS1 DeepImpute 0.0\n",
      "DS1 MAGIC 0.0\n",
      "DS2 Clean 0.468\n",
      "DS2 Noisy 0.006000000000000001\n",
      "DS2 SAUCIE 0.0\n",
      "DS2 scScope 0.0\n",
      "DS2 DeepImpute 0.006000000000000001\n",
      "DS2 MAGIC 0.0\n",
      "DS3 Clean 0.31600000000000006\n",
      "DS3 Noisy 0.0\n",
      "DS3 SAUCIE 0.004\n",
      "DS3 scScope 0.002\n",
      "DS3 DeepImpute 0.002\n",
      "DS3 MAGIC 0.002\n",
      "Running Pearson ranking tests with proportion 0.3\n",
      "DS1 Clean 0.57\n",
      "DS1 Noisy 0.06\n",
      "DS1 SAUCIE 0.002\n",
      "DS1 scScope 0.0\n",
      "DS1 DeepImpute 0.0\n",
      "DS1 MAGIC 0.0\n",
      "DS2 Clean 0.496\n",
      "DS2 Noisy 0.02\n",
      "DS2 SAUCIE 0.0\n",
      "DS2 scScope 0.002\n",
      "DS2 DeepImpute 0.002\n",
      "DS2 MAGIC 0.0\n",
      "DS3 Clean 0.396\n",
      "DS3 Noisy 0.008\n",
      "DS3 SAUCIE 0.006000000000000001\n",
      "DS3 scScope 0.0\n",
      "DS3 DeepImpute 0.0\n",
      "DS3 MAGIC 0.0\n"
     ]
    }
   ],
   "source": [
    "run_pearson_ranking(0.1)\n",
    "run_pearson_ranking(0.2)\n",
    "run_pearson_ranking(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "import random\n",
    "\n",
    "def run_pearson_edge_sampling(proportion):\n",
    "    print(\"Running Pearson edge sampling tests with proportion\", proportion)\n",
    "    imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        if i == 1:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/gt_GRN.csv'\n",
    "        elif i == 2:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/gt_GRN.csv'\n",
    "        elif i == 3:\n",
    "            gt_file = 'SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/gt_GRN.csv'\n",
    "        \n",
    "        methods = ['Clean', 'Noisy', 'SAUCIE', 'scScope', 'DeepImpute', 'MAGIC']\n",
    "        \n",
    "        for method in methods:\n",
    "            file_name = f'DS{i}_{method}.csv'  # Adjusted for simplicity\n",
    "            load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "            data_file_path = os.path.join(load_dir, file_name)\n",
    "\n",
    "            if not os.path.exists(data_file_path):\n",
    "                print(f\"File {data_file_path} does not exist. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            clean_df = pd.read_csv(data_file_path)\n",
    "            gt = pd.read_csv(gt_file, header=None)\n",
    "            \n",
    "            confirmed_edges = set(tuple(x) for x in gt.values)\n",
    "            \n",
    "            all_possible_edges = [(row, col) for row in clean_df.columns for col in clean_df.columns if row != col]\n",
    "            num_edges_to_sample = int(len(all_possible_edges) * proportion)\n",
    "            \n",
    "            total = 0\n",
    "            for r in range(50):\n",
    "                sampled_edges = random.sample(all_possible_edges, num_edges_to_sample)\n",
    "                matches = 0\n",
    "                for edge in sampled_edges:\n",
    "                    gene1, gene2 = edge\n",
    "                    corr, _ = pearsonr(clean_df[gene1], clean_df[gene2])\n",
    "                    # Check if this edge is in the confirmed edges and if the correlation is significant\n",
    "                    if edge in confirmed_edges and abs(corr) > 0.5:  # Threshold for \"significant\" correlation can be adjusted\n",
    "                        matches += 1\n",
    "                prop = matches / len(sampled_edges)\n",
    "                total += prop\n",
    "            \n",
    "            print(f\"DS{i} {method}: Proportion of significant confirmed edges = {total / 50}\")\n",
    "\n",
    "# Example usage\n",
    "proportion = 0.1\n",
    "run_pearson_edge_sampling(proportion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel_utils import process_iteration\n",
    "import concurrent\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def edge_finding_experiment():\n",
    "    print(\"Running edge finding experiment\")\n",
    "    for i in range(1, 4):\n",
    "        gt_file = None\n",
    "        if i == 1:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/gt_GRN.csv'\n",
    "            target_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/Interaction_cID_4.txt'\n",
    "            regs_path = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/Regs_cID_4.txt'\n",
    "        elif i == 2:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/gt_GRN.csv'\n",
    "            target_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/Interaction_cID_5.txt'\n",
    "            regs_path = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/Regs_cID_5.txt'\n",
    "        elif i == 3:\n",
    "            gt_file = 'SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/gt_GRN.csv'\n",
    "            target_file = './SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/Interaction_cID_6.txt'\n",
    "            regs_path = './SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/Regs_cID_6.txt'\n",
    "        \n",
    "        reg_df = pd.read_csv(regs_path, header=None)\n",
    "        master_regs = [int(m) for m in reg_df[0].values]\n",
    "        true_pearson = pd.DataFrame()\n",
    "        gt = pd.read_csv(gt_file, header=None)\n",
    "        imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "        load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "        ranks = []\n",
    "        correlations = []\n",
    "        with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "            futures = []\n",
    "            for iteration in tqdm(range(0, 51)):\n",
    "                file_extension = ''\n",
    "                if iteration == 0:\n",
    "                    #print('unchanged version')\n",
    "                    #run_sergio(target_file, regs_path, i, file_extension)\n",
    "                    clean_df = pd.DataFrame(np.load(os.path.join(load_dir, f\"DS6_clean{file_extension}.npy\")))\n",
    "                    true_pearson = Pearson(np.transpose(clean_df), '')\n",
    "                    p_values = true_pearson.values\n",
    "                    np.fill_diagonal(p_values, 0)\n",
    "                    true_pearson = pd.DataFrame(p_values, index=true_pearson.columns, columns=true_pearson.columns)\n",
    "                else:\n",
    "                    file_extension = f'_iter{iteration}'\n",
    "                    futures.append(executor.submit(process_iteration, iteration, target_file, regs_path, master_regs, load_dir, imp_dir, i, file_extension))\n",
    "            for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "                pearson, chosen_pair, temp_target, f_ext = future.result()\n",
    "                regulator_row = pearson.loc[chosen_pair[0]]\n",
    "                true_regulator_row = true_pearson.loc[chosen_pair[0]]\n",
    "                \n",
    "                # Take difference between calculated and true values\n",
    "                abs_diff = np.abs(true_regulator_row - regulator_row)\n",
    "                sorted_row = abs_diff.sort_values(ascending=False)\n",
    "\n",
    "                #print(abs_diff.index(chosen_pair[1]), sorted_row.index(chosen_pair[1]))\n",
    "                rank_target = sorted_row.index.get_loc(chosen_pair[1])\n",
    "                ranks.append(rank_target)\n",
    "                rank_value = sorted_row.iloc[rank_target]\n",
    "                correlations.append(rank_value)\n",
    "\n",
    "                        #rank_value = sorted_row.iloc[rank_target]\n",
    "                        \n",
    "                print(chosen_pair[0], chosen_pair[1], rank_target, rank_value)\n",
    "                        #print(\"Current iteration:\", iteration, f\"Mean rankings for DS{i} added edge:\", np.mean(ranks), np.mean(correlations))\n",
    "                        # delete temp file\n",
    "                os.remove(temp_target)\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_clean{f_ext}.npy\"))\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_clean_counts{f_ext}.npy\"))\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_noisy{f_ext}.npy\"))\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_expr{f_ext}.npy\"))\n",
    "                        #print(chosen_pair[0], regulator_row)\n",
    "                        #print(chosen_pair[0], regulator_row.sort_values(ascending=False))\n",
    "            print(f\"Mean rankings for DS{iteration} added edge:\", np.mean(ranks), np.mean(correlations))               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running edge finding experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 571.73it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "WARNING:tensorflow:From /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/venv/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/venv/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/venv/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/venv/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "  2%|▏         | 1/50 [01:23<1:07:53, 83.14s/it]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS1/DS6_clean.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/process.py\", line 261, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/parallel_utils.py\", line 79, in process_iteration\n    clean_df = pd.DataFrame(np.load(os.path.join(load_dir, f\"DS6_clean{file_extension}.npy\")))\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/venv/lib/python3.11/site-packages/numpy/lib/npyio.py\", line 405, in load\n    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS1/DS6_clean.npy'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43medge_finding_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[74], line 46\u001b[0m, in \u001b[0;36medge_finding_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         futures\u001b[38;5;241m.\u001b[39mappend(executor\u001b[38;5;241m.\u001b[39msubmit(process_iteration, iteration, target_file, regs_path, master_regs, load_dir, imp_dir, i))\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(futures), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(futures)):\n\u001b[0;32m---> 46\u001b[0m     pearson, chosen_pair, temp_target, f_ext \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     regulator_row \u001b[38;5;241m=\u001b[39m pearson\u001b[38;5;241m.\u001b[39mloc[chosen_pair[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m     48\u001b[0m     true_regulator_row \u001b[38;5;241m=\u001b[39m true_pearson\u001b[38;5;241m.\u001b[39mloc[chosen_pair[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS1/DS6_clean.npy'"
     ]
    }
   ],
   "source": [
    "edge_finding_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero_imputation_venv",
   "language": "python",
   "name": "zero_imputation_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
