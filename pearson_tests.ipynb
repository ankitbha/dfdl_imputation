{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from consolidated_runs import run_simulations\n",
    "\n",
    "from Pearson.pearson import Pearson\n",
    "\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_with_proportion(total, targets, proportion):\n",
    "    total_sample = 10\n",
    "    num_special = int(total_sample * proportion)\n",
    "    special = np.random.choice(targets, num_special, replace=False)\n",
    "\n",
    "    remaining = list(set(total) - set(targets))\n",
    "    normal = np.random.choice(remaining, total_sample - num_special, replace=False)\n",
    "\n",
    "    final = np.concatenate([special, normal])\n",
    "    np.random.shuffle(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = range(1, 4) # DS3\n",
    "run_simulations(datasets,\n",
    "            sergio=True,\n",
    "            saucie=True, \n",
    "            scScope=True, \n",
    "            deepImpute=True, \n",
    "            magic=True, \n",
    "            genie=False,\n",
    "            arboreto=False,\n",
    "            pearson=False,\n",
    "            roc=False,\n",
    "            precision_recall_k=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations\n",
      "(9, 100, 300)\n",
      "(9, 400, 300)\n",
      "(9, 400, 300)\n",
      "(9, 1200, 300)\n",
      "(9, 1200, 300)\n"
     ]
    }
   ],
   "source": [
    "imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "print(imp_dir)\n",
    "for i in range(1, 4):\n",
    "    load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "    save_name = 'DS6_expr.npy'\n",
    "\n",
    "    expr = np.load(os.path.join(load_dir, save_name))\n",
    "    print(expr.shape)\n",
    "    file_name = 'expr_shape.csv'\n",
    "    if not os.path.exists(os.path.join(load_dir, file_name)):\n",
    "        npfile = np.load(os.path.join(load_dir, save_name))\n",
    "        shap = npfile.shape\n",
    "        print(shap)\n",
    "        df = pd.DataFrame([shap])\n",
    "        df.to_csv(load_dir + '/' + file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "\n",
    "def run_pearson_ranking(proportion):\n",
    "    print(\"Running Pearson ranking tests with proportion\", proportion)\n",
    "    for i in range(1, 4):\n",
    "        gt_file = None\n",
    "        if i == 1:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/gt_GRN.csv'\n",
    "        elif i == 2:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/gt_GRN.csv'\n",
    "        elif i == 3:\n",
    "            gt_file = 'SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/gt_GRN.csv'\n",
    "        \n",
    "        # For now, just load clean data, save as csv, and load it back in\n",
    "        methods = ['Clean', 'Noisy', 'SAUCIE', 'scScope', 'DeepImpute', 'MAGIC']\n",
    "        file_name = ''\n",
    "        save_name = ''\n",
    "        for method in methods:\n",
    "            if method == 'Clean':\n",
    "                file_name = f'DS6_clean.npy'\n",
    "                save_name = f'DS6_clean.csv'\n",
    "            elif method == 'Noisy':\n",
    "                file_name = f'DS6_45.npy'\n",
    "                save_name = f'DS6_45.csv'\n",
    "            elif method == 'SAUCIE':\n",
    "                file_name = f'yhat_SAUCIE.npy'\n",
    "                save_name = f'yhat_SAUCIE.csv'\n",
    "            elif method == 'scScope':\n",
    "                file_name = f'yhat_scScope.npy'\n",
    "                save_name = f'yhat_scScope.csv'\n",
    "            elif method == 'DeepImpute':\n",
    "                file_name = f'yhat_deepImpute.npy'\n",
    "                save_name = f'yhat_deepImpute.csv'\n",
    "            elif method == 'MAGIC':\n",
    "                file_name = f'yhat_MAGIC_t_auto.npy'\n",
    "                save_name = f'yhat_MAGIC_t_auto.csv'\n",
    "            load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "            if not os.path.exists(os.path.join(imp_dir, f'DS{i}', save_name)):\n",
    "                npfile = np.load(load_dir + '/' + file_name)\n",
    "                df = pd.DataFrame(npfile)\n",
    "                df.to_csv(load_dir + '/' + save_name, index=False)\n",
    "            clean_df = pd.read_csv(os.path.join(load_dir, save_name))\n",
    "            \n",
    "            # Read ground truth\n",
    "            gt = pd.read_csv(gt_file, header=None)\n",
    "            confirmed_genes = gt[0].unique()\n",
    "\n",
    "            # Run Pearson on clean and noisy data\n",
    "            pearson = Pearson(np.transpose(clean_df), '')\n",
    "            p_values = pearson.values\n",
    "            np.fill_diagonal(p_values, 0)\n",
    "            pearson = pd.DataFrame(p_values, index=pearson.columns, columns=pearson.columns)\n",
    "\n",
    "            total = 0\n",
    "            for r in range(50):\n",
    "                sampled = sample_with_proportion(clean_df.index.tolist(), confirmed_genes, proportion)\n",
    "            # Take subset of pearson data with only the sampled genes\n",
    "                p_subset = pearson.loc[sampled]\n",
    "            #print(p_subset)\n",
    "            # Rank the expression pairs by the absolute value of the pearson correlation\n",
    "                melted = pd.melt(p_subset.reset_index(), id_vars=['index'], value_vars=p_subset.columns)\n",
    "                melted.columns = ['input', 'target', 'correlation']\n",
    "                melted_sorted = melted.sort_values(by='correlation', ascending=False)\n",
    "                ranked_list = list(melted_sorted.itertuples(index=False, name=None))[:10]\n",
    "            # Calculate the proportion of confirmed genes in the top k of the ranked pairs\n",
    "                top_10 = [(input, target) for input, target, _ in ranked_list]\n",
    "                true_pairs = set(tuple(x) for x in gt.values)\n",
    "                matches = sum(1 for pair in top_10 if pair in true_pairs)\n",
    "                prop = matches / len(top_10)\n",
    "                total += prop\n",
    "\n",
    "            print(f\"DS{i}\", method, total / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Pearson ranking tests with proportion 0.1\n",
      "DS1 Clean 0.17999999999999997\n",
      "DS1 Noisy 0.042\n",
      "DS1 SAUCIE 0.0\n",
      "DS1 scScope 0.0\n",
      "DS1 DeepImpute 0.0\n",
      "DS1 MAGIC 0.0\n",
      "DS2 Clean 0.18799999999999997\n",
      "DS2 Noisy 0.002\n",
      "DS2 SAUCIE 0.0\n",
      "DS2 scScope 0.002\n",
      "DS2 DeepImpute 0.002\n",
      "DS2 MAGIC 0.0\n",
      "DS3 Clean 0.16999999999999996\n",
      "DS3 Noisy 0.0\n",
      "DS3 SAUCIE 0.004\n",
      "DS3 scScope 0.0\n",
      "DS3 DeepImpute 0.002\n",
      "DS3 MAGIC 0.0\n",
      "Running Pearson ranking tests with proportion 0.2\n",
      "DS1 Clean 0.374\n",
      "DS1 Noisy 0.05199999999999999\n",
      "DS1 SAUCIE 0.004\n",
      "DS1 scScope 0.0\n",
      "DS1 DeepImpute 0.0\n",
      "DS1 MAGIC 0.0\n",
      "DS2 Clean 0.468\n",
      "DS2 Noisy 0.006000000000000001\n",
      "DS2 SAUCIE 0.0\n",
      "DS2 scScope 0.0\n",
      "DS2 DeepImpute 0.006000000000000001\n",
      "DS2 MAGIC 0.0\n",
      "DS3 Clean 0.31600000000000006\n",
      "DS3 Noisy 0.0\n",
      "DS3 SAUCIE 0.004\n",
      "DS3 scScope 0.002\n",
      "DS3 DeepImpute 0.002\n",
      "DS3 MAGIC 0.002\n",
      "Running Pearson ranking tests with proportion 0.3\n",
      "DS1 Clean 0.57\n",
      "DS1 Noisy 0.06\n",
      "DS1 SAUCIE 0.002\n",
      "DS1 scScope 0.0\n",
      "DS1 DeepImpute 0.0\n",
      "DS1 MAGIC 0.0\n",
      "DS2 Clean 0.496\n",
      "DS2 Noisy 0.02\n",
      "DS2 SAUCIE 0.0\n",
      "DS2 scScope 0.002\n",
      "DS2 DeepImpute 0.002\n",
      "DS2 MAGIC 0.0\n",
      "DS3 Clean 0.396\n",
      "DS3 Noisy 0.008\n",
      "DS3 SAUCIE 0.006000000000000001\n",
      "DS3 scScope 0.0\n",
      "DS3 DeepImpute 0.0\n",
      "DS3 MAGIC 0.0\n"
     ]
    }
   ],
   "source": [
    "run_pearson_ranking(0.1)\n",
    "run_pearson_ranking(0.2)\n",
    "run_pearson_ranking(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from consolidated_runs import run_sergio\n",
    "\n",
    "def edge_finding_experiment():\n",
    "    print(\"Running edge finding experiment\")\n",
    "    for i in range(1, 4):\n",
    "        gt_file = None\n",
    "        if i == 1:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/gt_GRN.csv'\n",
    "            target_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/Interaction_cID_4.txt'\n",
    "            regs_path = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/Regs_cID_4.txt'\n",
    "        elif i == 2:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/gt_GRN.csv'\n",
    "            target_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/Interaction_cID_5.txt'\n",
    "            regs_path = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/Regs_cID_5.txt'\n",
    "        elif i == 3:\n",
    "            gt_file = 'SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/gt_GRN.csv'\n",
    "            target_file = './SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/Interaction_cID_6.txt'\n",
    "            regs_path = './SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/Regs_cID_6.txt'\n",
    "        \n",
    "        reg_df = pd.read_csv(regs_path, header=None)\n",
    "        master_regs = [int(r) for r in reg_df[0].values]\n",
    "        true_pearson = pd.DataFrame()\n",
    "        gt = pd.read_csv(gt_file, header=None)\n",
    "        imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "        load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "        for iteration in tqdm(range(0, 51)):\n",
    "            file_extension = ''\n",
    "            regulators = {}\n",
    "            targets = {}\n",
    "            chosen_pair = None\n",
    "            temp_target = None\n",
    "            ranks = []\n",
    "            correlations = []\n",
    "            if iteration == 0:\n",
    "                print('unchanged version')\n",
    "                run_sergio(target_file, regs_path, i, file_extension)\n",
    "                clean_df = pd.DataFrame(np.load(os.path.join(load_dir, f\"DS6_clean{file_extension}.npy\")))\n",
    "                true_pearson = Pearson(np.transpose(clean_df), '')\n",
    "                p_values = true_pearson.values\n",
    "                np.fill_diagonal(p_values, 0)\n",
    "                true_pearson = pd.DataFrame(p_values, index=true_pearson.columns, columns=true_pearson.columns)\n",
    "            else:\n",
    "                file_extension = f'_iter{iteration}'\n",
    "                with open(target_file, 'r') as file:\n",
    "                    lines = file.readlines()\n",
    "                    for line in lines:\n",
    "                        values = line.split(',')\n",
    "                        target = float(values[0])\n",
    "                        num_regs = int(float(values[1]))\n",
    "                        #print(values, target, num_regs)\n",
    "                        regs = [float(v) for v in values[2:2 + num_regs]]\n",
    "                        hill_values = [float(v) for v in values[2 + num_regs:]]\n",
    "                        other_hill_values = [v for v in hill_values[int(len(hill_values) / 2):]]\n",
    "                        for index, zipped in enumerate(zip(regs, hill_values, other_hill_values)):\n",
    "                            reg = zipped[0]\n",
    "                            hill = zipped[1]\n",
    "                            other_hill = zipped[2]\n",
    "                            if reg not in regulators:\n",
    "                                regulators[reg] = [(target, hill, other_hill)]\n",
    "                            else:\n",
    "                                regulators[reg].append((target, hill, other_hill))\n",
    "                            if target not in targets:\n",
    "                                targets[target] = [(reg, hill, other_hill)]\n",
    "                            else:\n",
    "                                targets[target].append((reg, hill, other_hill))\n",
    "                file.close()\n",
    "                temp_target = target_file.replace('.txt', f'_iter{iteration}_temp.txt')\n",
    "                # Get number of genes to choose a target\n",
    "                expr_name = 'DS6_expr.npy'\n",
    "                expr = np.load(os.path.join(load_dir, expr_name))\n",
    "                genes = expr.shape[1]\n",
    "                #print(genes)\n",
    "                chosen_target = random.randint(0, genes - 1)\n",
    "\n",
    "                chosen_regulator = random.choice(list(regulators.keys()))\n",
    "                min_hill = np.min([float(hill[1]) for hill in regulators[chosen_regulator]])\n",
    "                max_hill = np.max([float(hill[1]) for hill in regulators[chosen_regulator]])\n",
    "                random_hill = random.uniform(min_hill, max_hill)\n",
    "\n",
    "                while chosen_target in [t[0] for t in regulators[chosen_regulator]] or chosen_target in master_regs:\n",
    "                    chosen_target = random.randint(0, genes - 1)\n",
    "                \n",
    "                if chosen_target not in targets:\n",
    "                    targets[chosen_target] = [(chosen_regulator, random_hill, 2.0)]\n",
    "                else:\n",
    "                    targets[chosen_target].append((chosen_regulator, random_hill, 2.0))\n",
    "                \n",
    "                regulators[chosen_regulator].append((chosen_target, random_hill, 2.0))\n",
    "                chosen_pair = (chosen_regulator, chosen_target)\n",
    "                #print(chosen_pair)\n",
    "                with open(temp_target, 'w') as file_copy:\n",
    "                    for ind, target in enumerate(targets.items()):\n",
    "                        t = float(target[0])\n",
    "                        regs = float(len(target[1]))\n",
    "                        regulators = [str(x[0]) for x in target[1]]\n",
    "                        hill_values = [str(x[1]) for x in target[1]]\n",
    "                        other_hill_values = [str(x[2]) for x in target[1]]\n",
    "                        file_copy.write(f'{t},{regs},{\",\".join(regulators)},{\",\".join(hill_values)},{\",\".join(other_hill_values)}\\n')\n",
    "                run_sergio(temp_target, regs_path, i, file_extension)\n",
    "                \n",
    "                clean_df = pd.DataFrame(np.load(os.path.join(load_dir, f\"DS6_clean{file_extension}.npy\")))\n",
    "                pearson = Pearson(np.transpose(clean_df), '')\n",
    "                p_values = pearson.values\n",
    "                np.fill_diagonal(p_values, 0)\n",
    "                pearson = pd.DataFrame(p_values, index=pearson.columns, columns=pearson.columns)\n",
    "                regulator_row = pearson.loc[chosen_pair[0]]\n",
    "                true_regulator_row = true_pearson.loc[chosen_pair[0]]\n",
    "                # Take difference between calculated and true values\n",
    "                abs_diff = np.abs(true_regulator_row - regulator_row)\n",
    "                sorted_row = abs_diff.sort_values(ascending=False)\n",
    "                \n",
    "                rank_target = sorted_row.index.get_loc(chosen_pair[1])\n",
    "                ranks.append(rank_target)\n",
    "                rank_value = sorted_row.iloc[rank_target]\n",
    "                correlations.append(rank_value)\n",
    "\n",
    "                #rank_value = sorted_row.iloc[rank_target]\n",
    "                # print(regulator_row[chosen_pair[1]])\n",
    "                # print(true_regulator_row[chosen_pair[1]])\n",
    "                # print(abs_diff)\n",
    "                # print(sorted_row)\n",
    "                # print(chosen_pair[0], chosen_pair[1], rank_target, rank_value)\n",
    "                # delete temp file\n",
    "                os.remove(temp_target)\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_clean{file_extension}.npy\"))\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_clean_counts{file_extension}.npy\"))\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_noisy{file_extension}.npy\"))\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_expr{file_extension}.npy\"))\n",
    "\n",
    "                #print(chosen_pair[0], regulator_row)\n",
    "                #print(chosen_pair[0], regulator_row.sort_values(ascending=False))\n",
    "        print(f\"Mean rankings for DS{i} added edge:\", np.mean(ranks), np.mean(correlations))               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running edge finding experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unchanged version\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 15/51 [13:03<31:19, 52.21s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "edge_finding_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero_imputation_venv",
   "language": "python",
   "name": "zero_imputation_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
