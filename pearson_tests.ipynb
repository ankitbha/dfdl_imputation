{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from consolidated_runs import run_simulations\n",
    "\n",
    "from Pearson.pearson import Pearson\n",
    "\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_with_proportion(total, targets, proportion):\n",
    "    total_sample = 10\n",
    "    num_special = int(total_sample * proportion)\n",
    "    special = np.random.choice(targets, num_special, replace=False)\n",
    "\n",
    "    remaining = list(set(total) - set(targets))\n",
    "    normal = np.random.choice(remaining, total_sample - num_special, replace=False)\n",
    "\n",
    "    final = np.concatenate([special, normal])\n",
    "    np.random.shuffle(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = range(1, 4) # DS3\n",
    "run_simulations(datasets,\n",
    "            sergio=True,\n",
    "            saucie=True, \n",
    "            scScope=True, \n",
    "            deepImpute=True, \n",
    "            magic=True, \n",
    "            genie=False,\n",
    "            arboreto=False,\n",
    "            pearson=False,\n",
    "            roc=False,\n",
    "            precision_recall_k=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations\n",
      "(9, 100, 300)\n",
      "(9, 400, 300)\n",
      "(9, 400, 300)\n",
      "(9, 1200, 300)\n",
      "(9, 1200, 300)\n"
     ]
    }
   ],
   "source": [
    "imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "print(imp_dir)\n",
    "for i in range(1, 4):\n",
    "    load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "    save_name = 'DS6_expr.npy'\n",
    "\n",
    "    expr = np.load(os.path.join(load_dir, save_name))\n",
    "    print(expr.shape)\n",
    "    file_name = 'expr_shape.csv'\n",
    "    if not os.path.exists(os.path.join(load_dir, file_name)):\n",
    "        npfile = np.load(os.path.join(load_dir, save_name))\n",
    "        shap = npfile.shape\n",
    "        print(shap)\n",
    "        df = pd.DataFrame([shap])\n",
    "        df.to_csv(load_dir + '/' + file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "\n",
    "def run_pearson_ranking(proportion):\n",
    "    print(\"Running Pearson ranking tests with proportion\", proportion)\n",
    "    for i in range(1, 4):\n",
    "        gt_file = None\n",
    "        if i == 1:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/gt_GRN.csv'\n",
    "        elif i == 2:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/gt_GRN.csv'\n",
    "        elif i == 3:\n",
    "            gt_file = 'SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/gt_GRN.csv'\n",
    "        \n",
    "        # For now, just load clean data, save as csv, and load it back in\n",
    "        methods = ['Clean', 'Noisy', 'SAUCIE', 'scScope', 'DeepImpute', 'MAGIC']\n",
    "        file_name = ''\n",
    "        save_name = ''\n",
    "        for method in methods:\n",
    "            if method == 'Clean':\n",
    "                file_name = f'DS6_clean.npy'\n",
    "                save_name = f'DS6_clean.csv'\n",
    "            elif method == 'Noisy':\n",
    "                file_name = f'DS6_45.npy'\n",
    "                save_name = f'DS6_45.csv'\n",
    "            elif method == 'SAUCIE':\n",
    "                file_name = f'yhat_SAUCIE.npy'\n",
    "                save_name = f'yhat_SAUCIE.csv'\n",
    "            elif method == 'scScope':\n",
    "                file_name = f'yhat_scScope.npy'\n",
    "                save_name = f'yhat_scScope.csv'\n",
    "            elif method == 'DeepImpute':\n",
    "                file_name = f'yhat_deepImpute.npy'\n",
    "                save_name = f'yhat_deepImpute.csv'\n",
    "            elif method == 'MAGIC':\n",
    "                file_name = f'yhat_MAGIC_t_auto.npy'\n",
    "                save_name = f'yhat_MAGIC_t_auto.csv'\n",
    "            load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "            if not os.path.exists(os.path.join(imp_dir, f'DS{i}', save_name)):\n",
    "                npfile = np.load(load_dir + '/' + file_name)\n",
    "                df = pd.DataFrame(npfile)\n",
    "                df.to_csv(load_dir + '/' + save_name, index=False)\n",
    "            clean_df = pd.read_csv(os.path.join(load_dir, save_name))\n",
    "            \n",
    "            # Read ground truth\n",
    "            gt = pd.read_csv(gt_file, header=None)\n",
    "            confirmed_genes = gt[0].unique()\n",
    "\n",
    "            # Run Pearson on clean and noisy data\n",
    "            pearson = Pearson(np.transpose(clean_df), '')\n",
    "            p_values = pearson.values\n",
    "            np.fill_diagonal(p_values, 0)\n",
    "            pearson = pd.DataFrame(p_values, index=pearson.columns, columns=pearson.columns)\n",
    "\n",
    "            total = 0\n",
    "            for r in range(50):\n",
    "                sampled = sample_with_proportion(clean_df.index.tolist(), confirmed_genes, proportion)\n",
    "            # Take subset of pearson data with only the sampled genes\n",
    "                p_subset = pearson.loc[sampled]\n",
    "            #print(p_subset)\n",
    "            # Rank the expression pairs by the absolute value of the pearson correlation\n",
    "                melted = pd.melt(p_subset.reset_index(), id_vars=['index'], value_vars=p_subset.columns)\n",
    "                melted.columns = ['input', 'target', 'correlation']\n",
    "                melted_sorted = melted.sort_values(by='correlation', ascending=False)\n",
    "                ranked_list = list(melted_sorted.itertuples(index=False, name=None))[:10]\n",
    "            # Calculate the proportion of confirmed genes in the top k of the ranked pairs\n",
    "                top_10 = [(input, target) for input, target, _ in ranked_list]\n",
    "                true_pairs = set(tuple(x) for x in gt.values)\n",
    "                matches = sum(1 for pair in top_10 if pair in true_pairs)\n",
    "                prop = matches / len(top_10)\n",
    "                total += prop\n",
    "\n",
    "            print(f\"DS{i}\", method, total / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Pearson ranking tests with proportion 0.1\n",
      "DS1 Clean 0.17999999999999997\n",
      "DS1 Noisy 0.042\n",
      "DS1 SAUCIE 0.0\n",
      "DS1 scScope 0.0\n",
      "DS1 DeepImpute 0.0\n",
      "DS1 MAGIC 0.0\n",
      "DS2 Clean 0.18799999999999997\n",
      "DS2 Noisy 0.002\n",
      "DS2 SAUCIE 0.0\n",
      "DS2 scScope 0.002\n",
      "DS2 DeepImpute 0.002\n",
      "DS2 MAGIC 0.0\n",
      "DS3 Clean 0.16999999999999996\n",
      "DS3 Noisy 0.0\n",
      "DS3 SAUCIE 0.004\n",
      "DS3 scScope 0.0\n",
      "DS3 DeepImpute 0.002\n",
      "DS3 MAGIC 0.0\n",
      "Running Pearson ranking tests with proportion 0.2\n",
      "DS1 Clean 0.374\n",
      "DS1 Noisy 0.05199999999999999\n",
      "DS1 SAUCIE 0.004\n",
      "DS1 scScope 0.0\n",
      "DS1 DeepImpute 0.0\n",
      "DS1 MAGIC 0.0\n",
      "DS2 Clean 0.468\n",
      "DS2 Noisy 0.006000000000000001\n",
      "DS2 SAUCIE 0.0\n",
      "DS2 scScope 0.0\n",
      "DS2 DeepImpute 0.006000000000000001\n",
      "DS2 MAGIC 0.0\n",
      "DS3 Clean 0.31600000000000006\n",
      "DS3 Noisy 0.0\n",
      "DS3 SAUCIE 0.004\n",
      "DS3 scScope 0.002\n",
      "DS3 DeepImpute 0.002\n",
      "DS3 MAGIC 0.002\n",
      "Running Pearson ranking tests with proportion 0.3\n",
      "DS1 Clean 0.57\n",
      "DS1 Noisy 0.06\n",
      "DS1 SAUCIE 0.002\n",
      "DS1 scScope 0.0\n",
      "DS1 DeepImpute 0.0\n",
      "DS1 MAGIC 0.0\n",
      "DS2 Clean 0.496\n",
      "DS2 Noisy 0.02\n",
      "DS2 SAUCIE 0.0\n",
      "DS2 scScope 0.002\n",
      "DS2 DeepImpute 0.002\n",
      "DS2 MAGIC 0.0\n",
      "DS3 Clean 0.396\n",
      "DS3 Noisy 0.008\n",
      "DS3 SAUCIE 0.006000000000000001\n",
      "DS3 scScope 0.0\n",
      "DS3 DeepImpute 0.0\n",
      "DS3 MAGIC 0.0\n"
     ]
    }
   ],
   "source": [
    "run_pearson_ranking(0.1)\n",
    "run_pearson_ranking(0.2)\n",
    "run_pearson_ranking(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from consolidated_runs import run_sergio\n",
    "\n",
    "def edge_finding_experiment():\n",
    "    print(\"Running edge finding experiment\")\n",
    "    for i in range(1, 4):\n",
    "        gt_file = None\n",
    "        if i == 1:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/gt_GRN.csv'\n",
    "            target_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/Interaction_cID_4.txt'\n",
    "            regs_path = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/Regs_cID_4.txt'\n",
    "        elif i == 2:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/gt_GRN.csv'\n",
    "            target_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/Interaction_cID_5.txt'\n",
    "            regs_path = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/Regs_cID_5.txt'\n",
    "        elif i == 3:\n",
    "            gt_file = 'SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/gt_GRN.csv'\n",
    "            target_file = './SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/Interaction_cID_6.txt'\n",
    "            regs_path = './SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/Regs_cID_6.txt'\n",
    "        \n",
    "        reg_df = pd.read_csv(regs_path, header=None)\n",
    "        master_regs = [int(i) for i in reg_df[0].values]\n",
    "        for iteration in tqdm(range(0, 51)):\n",
    "            file_extension = ''\n",
    "            regulators = {}\n",
    "            targets = {}\n",
    "            chosen_pair = None\n",
    "            temp_target = None\n",
    "            ranks = []\n",
    "            correlations = []\n",
    "            if iteration == 0:\n",
    "                #print('unchanged version')\n",
    "                #run_sergio(target_file, regs_path, i, file_extension)\n",
    "                temp_target = target_file\n",
    "            else:\n",
    "                file_extension = f'_iter{iteration}'\n",
    "                with open(target_file, 'r') as file:\n",
    "                    lines = file.readlines()\n",
    "                    for line in lines:\n",
    "                        values = line.split(',')\n",
    "                        target = float(values[0])\n",
    "                        num_regs = int(float(values[1]))\n",
    "                        #print(values, target, num_regs)\n",
    "                        regs = [float(v) for v in values[2:2 + num_regs]]\n",
    "                        hill_values = [float(v) for v in values[2 + num_regs:]]\n",
    "                        other_hill_values = [v for v in hill_values[int(len(hill_values) / 2):]]\n",
    "                        for i, zipped in enumerate(zip(regs, hill_values, other_hill_values)):\n",
    "                            reg = zipped[0]\n",
    "                            hill = zipped[1]\n",
    "                            other_hill = zipped[2]\n",
    "                            if reg not in regulators:\n",
    "                                regulators[reg] = [(target, hill, other_hill)]\n",
    "                            else:\n",
    "                                regulators[reg].append((target, hill, other_hill))\n",
    "                            if target not in targets:\n",
    "                                targets[target] = [(reg, hill, other_hill)]\n",
    "                            else:\n",
    "                                targets[target].append((reg, hill, other_hill))\n",
    "                file.close()\n",
    "                temp_target = target_file.replace('.txt', f'_iter{iteration}_temp.txt')\n",
    "                # Get number of genes to choose a target\n",
    "                imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "                load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "                expr_name = 'DS6_expr.npy'\n",
    "                expr = np.load(os.path.join(load_dir, expr_name))\n",
    "                genes = expr.shape[1]\n",
    "                #print(genes)\n",
    "                chosen_target = random.randint(0, genes - 1)\n",
    "\n",
    "                chosen_regulator = random.choice(list(regulators.keys()))\n",
    "                min_hill = np.min([float(hill[1]) for hill in regulators[chosen_regulator]])\n",
    "                max_hill = np.max([float(hill[1]) for hill in regulators[chosen_regulator]])\n",
    "                random_hill = random.uniform(min_hill, max_hill)\n",
    "\n",
    "                while chosen_target in [t[0] for t in regulators[chosen_regulator]] or chosen_target in master_regs:\n",
    "                    chosen_target = random.randint(0, genes - 1)\n",
    "                \n",
    "                if chosen_target not in targets:\n",
    "                    targets[chosen_target] = [(chosen_regulator, random_hill, 2.0)]\n",
    "                else:\n",
    "                    targets[chosen_target].append((chosen_regulator, random_hill, 2.0))\n",
    "                \n",
    "                regulators[chosen_regulator].append((chosen_target, random_hill, 2.0))\n",
    "                chosen_pair = (chosen_regulator, chosen_target)\n",
    "                #print(chosen_pair)\n",
    "                with open(temp_target, 'w') as file_copy:\n",
    "                    for ind, target in enumerate(targets.items()):\n",
    "                        t = float(target[0])\n",
    "                        regs = float(len(target[1]))\n",
    "                        regulators = [str(x[0]) for x in target[1]]\n",
    "                        hill_values = [str(x[1]) for x in target[1]]\n",
    "                        other_hill_values = [str(x[2]) for x in target[1]]\n",
    "                        file_copy.write(f'{t},{regs},{\",\".join(regulators)},{\",\".join(hill_values)},{\",\".join(other_hill_values)}\\n')\n",
    "                run_sergio(temp_target, regs_path, i, file_extension)\n",
    "            if iteration != 0:\n",
    "                gt = pd.read_csv(gt_file, header=None)\n",
    "                confirmed_genes = gt[0].unique()\n",
    "                clean_df = pd.DataFrame(np.load(os.path.join(load_dir, f\"DS6_clean{file_extension}.npy\")))\n",
    "                pearson = Pearson(np.transpose(clean_df), '')\n",
    "                p_values = pearson.values\n",
    "                np.fill_diagonal(p_values, 0)\n",
    "                pearson = pd.DataFrame(p_values, index=pearson.columns, columns=pearson.columns)\n",
    "                regulator_row = pearson.loc[chosen_pair[0]]\n",
    "                sorted_row = regulator_row.sort_values(ascending=False)\n",
    "                rank_target = sorted_row.index.get_loc(chosen_pair[1])\n",
    "                ranks.append(rank_target)\n",
    "                rank_value = sorted_row.iloc[rank_target]\n",
    "                correlations.append(rank_value)\n",
    "\n",
    "                #rank_value = sorted_row.iloc[rank_target]\n",
    "                \n",
    "                #print(chosen_pair[0], chosen_pair[1], rank_target, rank_value)\n",
    "                # delete temp file\n",
    "                os.remove(temp_target)\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_clean{file_extension}.npy\"))\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_clean_counts{file_extension}.npy\"))\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_noisy{file_extension}.npy\"))\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_expr{file_extension}.npy\"))\n",
    "\n",
    "                #print(chosen_pair[0], regulator_row)\n",
    "                #print(chosen_pair[0], regulator_row.sort_values(ascending=False))\n",
    "        print(f\"Mean rankings for DS{i} added edge:\", np.mean(ranks), np.mean(correlations))               \n",
    "\n",
    "        # For now, just load clean data, save as csv, and load it back in\n",
    "        methods = ['Clean']#, 'Noisy', 'SAUCIE', 'scScope', 'DeepImpute', 'MAGIC']\n",
    "        file_name = ''\n",
    "        save_name = ''\n",
    "        \n",
    "        load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "        if not os.path.exists(os.path.join(imp_dir, f'DS{i}', save_name)):\n",
    "            npfile = np.load(load_dir + '/' + file_name)\n",
    "            df = pd.DataFrame(npfile)\n",
    "            df.to_csv(load_dir + '/' + save_name, index=False)\n",
    "        clean_df = pd.read_csv(os.path.join(load_dir, save_name))\n",
    "        \n",
    "        # Read ground truth\n",
    "        gt = pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running edge finding experiment\n",
      "unchanged version\n",
      "100\n",
      "(74.0, 29)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[143], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43medge_finding_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[142], line 93\u001b[0m, in \u001b[0;36medge_finding_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m             other_hill_values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(x[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m target[\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m     92\u001b[0m             file_copy\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(regulators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(hill_values)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(other_hill_values)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m     \u001b[43mrun_sergio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregs_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_extension\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iteration \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     95\u001b[0m     gt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(gt_file, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Folders/Projects/zero_imputation/consolidated_runs.py:62\u001b[0m, in \u001b[0;36mrun_sergio\u001b[0;34m(input_file, reg_file, ind, file_extension)\u001b[0m\n\u001b[1;32m     51\u001b[0m sim \u001b[38;5;241m=\u001b[39m sergio(\n\u001b[1;32m     52\u001b[0m     number_genes\u001b[38;5;241m=\u001b[39mn_genes, \n\u001b[1;32m     53\u001b[0m     number_bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     sampling_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, \n\u001b[1;32m     60\u001b[0m     noise_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdpd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     61\u001b[0m sim\u001b[38;5;241m.\u001b[39mbuild_graph(input_file_taregts\u001b[38;5;241m=\u001b[39minput_file, input_file_regs\u001b[38;5;241m=\u001b[39mreg_file, shared_coop_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m \u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Get Expression Data\u001b[39;00m\n\u001b[1;32m     65\u001b[0m expr \u001b[38;5;241m=\u001b[39m sim\u001b[38;5;241m.\u001b[39mgetExpressions()\n",
      "File \u001b[0;32m~/Desktop/Folders/Projects/zero_imputation/SERGIO/SERGIO/sergio.py:525\u001b[0m, in \u001b[0;36msergio.simulate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimulate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxLevels_, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;66;03m#print (\"Start simulating new level\")\u001b[39;00m\n\u001b[0;32m--> 525\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLE_simulator_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Folders/Projects/zero_imputation/SERGIO/SERGIO/sergio.py:478\u001b[0m, in \u001b[0;36msergio.CLE_simulator_\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m    476\u001b[0m binID \u001b[38;5;241m=\u001b[39m gObj\u001b[38;5;241m.\u001b[39mbinID\n\u001b[1;32m    477\u001b[0m \u001b[38;5;66;03m#print gObj.Conc\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m \u001b[43mgObj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend_Conc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgObj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcurr_dx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbIDX\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m gObj\u001b[38;5;241m.\u001b[39mincrementStep()\n\u001b[1;32m    482\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03mThe below section is commented since for steady state simulation we do not need to check convergence.\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03mIn fact, in steady state simulation we already start from converged region!\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;124;03m###########################################################################\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Folders/Projects/zero_imputation/SERGIO/SERGIO/gene.py:27\u001b[0m, in \u001b[0;36mgene.append_Conc\u001b[0;34m(self, currConc)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mss_U_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m#This is the steady state concentration of Unspliced mRNA\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mss_S_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m#This is the steady state concentration of Spliced mRNA\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mappend_Conc\u001b[39m (\u001b[38;5;28mself\u001b[39m, currConc):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(currConc, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m currConc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "edge_finding_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero_imputation_venv",
   "language": "python",
   "name": "zero_imputation_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
