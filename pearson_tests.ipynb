{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/venv/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from consolidated_runs import run_simulations\n",
    "\n",
    "from Pearson.pearson import Pearson\n",
    "\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_with_proportion(total, targets, proportion):\n",
    "    total_sample = 10\n",
    "    num_special = int(total_sample * proportion)\n",
    "    special = np.random.choice(targets, num_special, replace=False)\n",
    "\n",
    "    remaining = list(set(total) - set(targets))\n",
    "    normal = np.random.choice(remaining, total_sample - num_special, replace=False)\n",
    "\n",
    "    final = np.concatenate([special, normal])\n",
    "    np.random.shuffle(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = range(1, 4) # DS3\n",
    "run_simulations(datasets,\n",
    "            sergio=True,\n",
    "            saucie=True, \n",
    "            scScope=True, \n",
    "            deepImpute=True, \n",
    "            magic=True, \n",
    "            genie=False,\n",
    "            arboreto=False,\n",
    "            pearson=False,\n",
    "            roc=False,\n",
    "            precision_recall_k=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations\n",
      "(9, 100, 300)\n",
      "(9, 400, 300)\n",
      "(9, 1200, 300)\n"
     ]
    }
   ],
   "source": [
    "imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "print(imp_dir)\n",
    "for i in range(1, 4):\n",
    "    load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "    save_name = 'DS6_expr.npy'\n",
    "\n",
    "    expr = np.load(os.path.join(load_dir, save_name))\n",
    "    print(expr.shape)\n",
    "    file_name = 'expr_shape.csv'\n",
    "    if not os.path.exists(os.path.join(load_dir, file_name)):\n",
    "        npfile = np.load(os.path.join(load_dir, save_name))\n",
    "        shap = npfile.shape\n",
    "        print(shap)\n",
    "        df = pd.DataFrame([shap])\n",
    "        df.to_csv(load_dir + '/' + file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "\n",
    "def run_pearson_ranking(proportion):\n",
    "    print(\"Running Pearson ranking tests with proportion\", proportion)\n",
    "    for i in range(1, 4):\n",
    "        gt_file = None\n",
    "        if i == 1:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/gt_GRN.csv'\n",
    "        elif i == 2:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/gt_GRN.csv'\n",
    "        elif i == 3:\n",
    "            gt_file = 'SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/gt_GRN.csv'\n",
    "        \n",
    "        # For now, just load clean data, save as csv, and load it back in\n",
    "        methods = ['Clean', 'Noisy', 'SAUCIE', 'scScope', 'DeepImpute', 'MAGIC']\n",
    "        file_name = ''\n",
    "        save_name = ''\n",
    "        for method in methods:\n",
    "            if method == 'Clean':\n",
    "                file_name = f'DS6_clean.npy'\n",
    "                save_name = f'DS6_clean.csv'\n",
    "            elif method == 'Noisy':\n",
    "                file_name = f'DS6_45.npy'\n",
    "                save_name = f'DS6_45.csv'\n",
    "            elif method == 'SAUCIE':\n",
    "                file_name = f'yhat_SAUCIE.npy'\n",
    "                save_name = f'yhat_SAUCIE.csv'\n",
    "            elif method == 'scScope':\n",
    "                file_name = f'yhat_scScope.npy'\n",
    "                save_name = f'yhat_scScope.csv'\n",
    "            elif method == 'DeepImpute':\n",
    "                file_name = f'yhat_deepImpute.npy'\n",
    "                save_name = f'yhat_deepImpute.csv'\n",
    "            elif method == 'MAGIC':\n",
    "                file_name = f'yhat_MAGIC_t_auto.npy'\n",
    "                save_name = f'yhat_MAGIC_t_auto.csv'\n",
    "            load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "            if not os.path.exists(os.path.join(imp_dir, f'DS{i}', save_name)):\n",
    "                npfile = np.load(load_dir + '/' + file_name)\n",
    "                df = pd.DataFrame(npfile)\n",
    "                df.to_csv(load_dir + '/' + save_name, index=False)\n",
    "            clean_df = pd.read_csv(os.path.join(load_dir, save_name))\n",
    "            \n",
    "            # Read ground truth\n",
    "            gt = pd.read_csv(gt_file, header=None)\n",
    "            confirmed_genes = gt[0].unique()\n",
    "\n",
    "            # Run Pearson on clean and noisy data\n",
    "            pearson = Pearson(np.transpose(clean_df), '')\n",
    "            p_values = pearson.values\n",
    "            np.fill_diagonal(p_values, 0)\n",
    "            pearson = pd.DataFrame(p_values, index=pearson.columns, columns=pearson.columns)\n",
    "\n",
    "            total = 0\n",
    "            for r in range(50):\n",
    "                sampled = sample_with_proportion(clean_df.index.tolist(), confirmed_genes, proportion)\n",
    "            # Take subset of pearson data with only the sampled genes\n",
    "                p_subset = pearson.loc[sampled]\n",
    "            #print(p_subset)\n",
    "            # Rank the expression pairs by the absolute value of the pearson correlation\n",
    "                melted = pd.melt(p_subset.reset_index(), id_vars=['index'], value_vars=p_subset.columns)\n",
    "                melted.columns = ['input', 'target', 'correlation']\n",
    "                melted_sorted = melted.sort_values(by='correlation', ascending=False)\n",
    "                ranked_list = list(melted_sorted.itertuples(index=False, name=None))[:10]\n",
    "            # Calculate the proportion of confirmed genes in the top k of the ranked pairs\n",
    "                top_10 = [(input, target) for input, target, _ in ranked_list]\n",
    "                true_pairs = set(tuple(x) for x in gt.values)\n",
    "                matches = sum(1 for pair in top_10 if pair in true_pairs)\n",
    "                prop = matches / len(top_10)\n",
    "                total += prop\n",
    "\n",
    "            print(f\"DS{i}\", method, total / 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Pearson ranking tests with proportion 0.1\n",
      "DS1 Clean 0.17999999999999997\n",
      "DS1 Noisy 0.042\n",
      "DS1 SAUCIE 0.0\n",
      "DS1 scScope 0.0\n",
      "DS1 DeepImpute 0.0\n",
      "DS1 MAGIC 0.0\n",
      "DS2 Clean 0.18799999999999997\n",
      "DS2 Noisy 0.002\n",
      "DS2 SAUCIE 0.0\n",
      "DS2 scScope 0.002\n",
      "DS2 DeepImpute 0.002\n",
      "DS2 MAGIC 0.0\n",
      "DS3 Clean 0.16999999999999996\n",
      "DS3 Noisy 0.0\n",
      "DS3 SAUCIE 0.004\n",
      "DS3 scScope 0.0\n",
      "DS3 DeepImpute 0.002\n",
      "DS3 MAGIC 0.0\n",
      "Running Pearson ranking tests with proportion 0.2\n",
      "DS1 Clean 0.374\n",
      "DS1 Noisy 0.05199999999999999\n",
      "DS1 SAUCIE 0.004\n",
      "DS1 scScope 0.0\n",
      "DS1 DeepImpute 0.0\n",
      "DS1 MAGIC 0.0\n",
      "DS2 Clean 0.468\n",
      "DS2 Noisy 0.006000000000000001\n",
      "DS2 SAUCIE 0.0\n",
      "DS2 scScope 0.0\n",
      "DS2 DeepImpute 0.006000000000000001\n",
      "DS2 MAGIC 0.0\n",
      "DS3 Clean 0.31600000000000006\n",
      "DS3 Noisy 0.0\n",
      "DS3 SAUCIE 0.004\n",
      "DS3 scScope 0.002\n",
      "DS3 DeepImpute 0.002\n",
      "DS3 MAGIC 0.002\n",
      "Running Pearson ranking tests with proportion 0.3\n",
      "DS1 Clean 0.57\n",
      "DS1 Noisy 0.06\n",
      "DS1 SAUCIE 0.002\n",
      "DS1 scScope 0.0\n",
      "DS1 DeepImpute 0.0\n",
      "DS1 MAGIC 0.0\n",
      "DS2 Clean 0.496\n",
      "DS2 Noisy 0.02\n",
      "DS2 SAUCIE 0.0\n",
      "DS2 scScope 0.002\n",
      "DS2 DeepImpute 0.002\n",
      "DS2 MAGIC 0.0\n",
      "DS3 Clean 0.396\n",
      "DS3 Noisy 0.008\n",
      "DS3 SAUCIE 0.006000000000000001\n",
      "DS3 scScope 0.0\n",
      "DS3 DeepImpute 0.0\n",
      "DS3 MAGIC 0.0\n"
     ]
    }
   ],
   "source": [
    "run_pearson_ranking(0.1)\n",
    "run_pearson_ranking(0.2)\n",
    "run_pearson_ranking(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Pearson edge sampling tests with proportion 0.1\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS1/DS1_Clean.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS1/DS1_Noisy.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS1/DS1_SAUCIE.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS1/DS1_scScope.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS1/DS1_DeepImpute.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS1/DS1_MAGIC.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS2/DS2_Clean.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS2/DS2_Noisy.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS2/DS2_SAUCIE.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS2/DS2_scScope.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS2/DS2_DeepImpute.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS2/DS2_MAGIC.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS3/DS3_Clean.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS3/DS3_Noisy.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS3/DS3_SAUCIE.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS3/DS3_scScope.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS3/DS3_DeepImpute.csv does not exist. Skipping.\n",
      "File /Users/joshuaweiner/Desktop/Folders/Projects/zero_imputation/imputations/DS3/DS3_MAGIC.csv does not exist. Skipping.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "import random\n",
    "\n",
    "def run_pearson_edge_sampling(proportion):\n",
    "    print(\"Running Pearson edge sampling tests with proportion\", proportion)\n",
    "    imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        if i == 1:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/gt_GRN.csv'\n",
    "        elif i == 2:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/gt_GRN.csv'\n",
    "        elif i == 3:\n",
    "            gt_file = 'SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/gt_GRN.csv'\n",
    "        \n",
    "        methods = ['Clean', 'Noisy', 'SAUCIE', 'scScope', 'DeepImpute', 'MAGIC']\n",
    "        \n",
    "        for method in methods:\n",
    "            file_name = f'DS{i}_{method}.csv'  # Adjusted for simplicity\n",
    "            load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "            data_file_path = os.path.join(load_dir, file_name)\n",
    "\n",
    "            if not os.path.exists(data_file_path):\n",
    "                print(f\"File {data_file_path} does not exist. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            clean_df = pd.read_csv(data_file_path)\n",
    "            gt = pd.read_csv(gt_file, header=None)\n",
    "            \n",
    "            confirmed_edges = set(tuple(x) for x in gt.values)\n",
    "            \n",
    "            all_possible_edges = [(row, col) for row in clean_df.columns for col in clean_df.columns if row != col]\n",
    "            num_edges_to_sample = int(len(all_possible_edges) * proportion)\n",
    "            \n",
    "            total = 0\n",
    "            for r in range(50):\n",
    "                sampled_edges = random.sample(all_possible_edges, num_edges_to_sample)\n",
    "                matches = 0\n",
    "                for edge in sampled_edges:\n",
    "                    gene1, gene2 = edge\n",
    "                    corr, _ = pearsonr(clean_df[gene1], clean_df[gene2])\n",
    "                    # Check if this edge is in the confirmed edges and if the correlation is significant\n",
    "                    if edge in confirmed_edges and abs(corr) > 0.5:  # Threshold for \"significant\" correlation can be adjusted\n",
    "                        matches += 1\n",
    "                prop = matches / len(sampled_edges)\n",
    "                total += prop\n",
    "            \n",
    "            print(f\"DS{i} {method}: Proportion of significant confirmed edges = {total / 50}\")\n",
    "\n",
    "# Example usage\n",
    "proportion = 0.1\n",
    "run_pearson_edge_sampling(proportion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel_utils import process_iteration\n",
    "import concurrent\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def edge_finding_experiment():\n",
    "    print(\"Running edge finding experiment\")\n",
    "    for i in range(2, 4):\n",
    "        gt_file = None\n",
    "        if i == 1:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/gt_GRN.csv'\n",
    "            target_file = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/Interaction_cID_4.txt'\n",
    "            regs_path = './SERGIO/data_sets/De-noised_100G_9T_300cPerT_4_DS1/Regs_cID_4.txt'\n",
    "        elif i == 2:\n",
    "            gt_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/gt_GRN.csv'\n",
    "            target_file = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/Interaction_cID_5.txt'\n",
    "            regs_path = './SERGIO/data_sets/De-noised_400G_9T_300cPerT_5_DS2/Regs_cID_5.txt'\n",
    "        elif i == 3:\n",
    "            gt_file = 'SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/gt_GRN.csv'\n",
    "            target_file = './SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/Interaction_cID_6.txt'\n",
    "            regs_path = './SERGIO/data_sets/De-noised_1200G_9T_300cPerT_6_DS3/Regs_cID_6.txt'\n",
    "        \n",
    "        reg_df = pd.read_csv(regs_path, header=None)\n",
    "        master_regs = [int(m) for m in reg_df[0].values]\n",
    "        true_pearson = pd.DataFrame()\n",
    "        gt = pd.read_csv(gt_file, header=None)\n",
    "        imp_dir = os.path.join(os.getcwd(), 'imputations')\n",
    "        load_dir = os.path.join(imp_dir, f'DS{i}')\n",
    "        ranks = []\n",
    "        correlations = []\n",
    "        with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "            futures = []\n",
    "            for iteration in tqdm(range(0, 51)):\n",
    "                file_extension = ''\n",
    "                if iteration == 0:\n",
    "                    #print('unchanged version')\n",
    "                    #run_sergio(target_file, regs_path, i, file_extension)\n",
    "                    clean_df = pd.DataFrame(np.load(os.path.join(load_dir, f\"DS6_clean{file_extension}.npy\")))\n",
    "                    true_pearson = Pearson(np.transpose(clean_df), '')\n",
    "                    p_values = true_pearson.values\n",
    "                    np.fill_diagonal(p_values, 0)\n",
    "                    true_pearson = pd.DataFrame(p_values, index=true_pearson.columns, columns=true_pearson.columns)\n",
    "                else:\n",
    "                    file_extension = f'_iter{iteration}'\n",
    "                    futures.append(executor.submit(process_iteration, iteration, target_file, regs_path, master_regs, load_dir, imp_dir, i, file_extension))\n",
    "            for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "                pearson, chosen_pair, temp_target, f_ext = future.result()\n",
    "                regulator_row = pearson.loc[chosen_pair[0]]\n",
    "                true_regulator_row = true_pearson.loc[chosen_pair[0]]\n",
    "                \n",
    "                # Take difference between calculated and true values\n",
    "                abs_diff = np.abs(true_regulator_row - regulator_row)\n",
    "                sorted_row = abs_diff.sort_values(ascending=False)\n",
    "\n",
    "                #print(abs_diff.index(chosen_pair[1]), sorted_row.index(chosen_pair[1]))\n",
    "                rank_target = sorted_row.index.get_loc(chosen_pair[1])\n",
    "                ranks.append(rank_target)\n",
    "                rank_value = sorted_row.iloc[rank_target]\n",
    "                correlations.append(rank_value)\n",
    "\n",
    "                        #rank_value = sorted_row.iloc[rank_target]\n",
    "                        \n",
    "                print(chosen_pair[0], chosen_pair[1], rank_target, rank_value)\n",
    "                print(\"Current iteration:\", iteration, f\"Mean rankings for DS{i} added edge:\", np.mean(ranks), np.mean(correlations))\n",
    "                        # delete temp file\n",
    "                os.remove(temp_target)\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_clean{f_ext}.npy\"))\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_clean_counts{f_ext}.npy\"))\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_noisy{f_ext}.npy\"))\n",
    "                os.remove(os.path.join(imp_dir, f'DS{i}', f\"DS6_expr{f_ext}.npy\"))\n",
    "                        #print(chosen_pair[0], regulator_row)\n",
    "                        #print(chosen_pair[0], regulator_row.sort_values(ascending=False))\n",
    "            print(f\"Mean rankings for DS{iteration} added edge:\", np.mean(ranks), np.mean(correlations))               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_finding_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero_imputation_venv",
   "language": "python",
   "name": "zero_imputation_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
